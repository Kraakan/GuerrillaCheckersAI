<html>
  <body>
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
      <div class="mermaid">
    
        classDiagram
          class AI {
            model
            player
            __init__(model, player)
            select_action(state)
          }
          class AI {
            device
            game
            model
            n_ai_actions
            player
            __init__(model_path, player, game, device, network_type)
            select_action(state)
          }
          class Agent {
            action_list : list
            device
            game
            memory
            n_actions
            optimizer
            player
            policy_net
            steps_done : int
            target_net
            __init__(player, game, device, network)
            optimize_model()
            push_memory(state, action, next_state, reward)
            select_action(state)
          }
          class DQN {
            layer1
            layer2
            layer3
            __init__(n_observations, n_actions)
            forward(x)
          }
          class DQN {
            layer1
            layer2
            layer3
            __init__(n_observations, n_actions)
            forward(x)
          }
          class DummyNet {
          }
          class HardCoded {
            action_list : list
            device
            game
            n_actions
            player
            policy_net
            steps_done : int
            target_net
            __init__(player, game, device)
            optimize_model()*
            push_memory(state, action, next_state, reward)*
            select_action(state)
          }
          class PettingZoo {
            _action_spaces : dict
            _cumulative_rewards
            _observation_spaces
            agent_name_mapping : dict
            agent_selection : int
            agents : list
            game
            infos
            metadata : dict
            observations
            possible_agents : list
            render_mode : NoneType
            rewards
            state
            terminations
            truncations
            __init__(render_mode, num_checkers)
            _get_info()
            _get_obs()
            close()*
            get_acting_player()
            get_valid_sample()
            observation_space(agent)
            observe(agent)
            reset(seed, options)
            step(action, acting_player)
          }
          class Random {
            action_list : list
            device
            game
            n_actions
            player
            policy_net
            steps_done : int
            target_net
            __init__(player, game, device)
            optimize_model()*
            push_memory(state, action, next_state, reward)*
            select_action(state)
          }
          class ReplayMemory {
            memory : deque
            __init__(capacity)
            __len__()
            push()
            sample(batch_size)
          }
          class ReplayMemory {
            memory : deque
            __init__(capacity)
            __len__()
            push()
            sample(batch_size)
          }
          class ReplayMemory {
            memory : deque
            __init__(capacity)
            __len__()
            push()
            sample(batch_size)
          }
          class basic {
            layer1
            layer2
            layer3
            __init__(n_observations, n_actions)
            forward(x)
          }
          class deep2 {
            layer1
            layer2
            layer3
            layer4
            __init__(n_observations, n_actions)
            forward(x)
          }
          class deep3 {
            layer1
            layer2
            layer3
            layer4
            layer5
            __init__(n_observations, n_actions)
            forward(x)
          }
          class deep4 {
            layer1
            layer2
            layer3
            layer4
            layer5
            layer6
            __init__(n_observations, n_actions)
            forward(x)
          }
          class dqn_Agent {
            action_list : list
            memory
            n_actions
            optimizer
            player
            policy_net
            target_net
            __init__(player)
            optimize_model()
            push_memory(state, action, next_state, reward)
            select_action(state)
          }
          class game {
            COINjump : NoneType, tuple
            big_reward_factor : float
            board
            checker_positions : list
            game_record : list
            guerrillas_turn : bool
            small_reward_factor : float
            starting_checkers_num : int
            __init__(num_checkers, small_reward_factor, big_reward_factor)
            capture_and_move(board, position, debug)
            check_surround(board, positions)
            get_COIN_moves(debug)
            get_current_state()
            get_game_result()
            get_guerrilla_moves()
            get_remaining_stones()
            get_reward(player)
            get_small_reward(player)
            get_valid_action_indexes(player)
            get_valid_actions(player)
            initialize_checkers()
            is_game_over()
            old_get_guerrilla_moves()
            reset()
            set_big_reward_factor(new_factor)
            set_num_checkers(new_num)
            set_small_reward_factor(new_factor)
            take_action(player, action)
          }
          class gym_env {
            action_space
            clock : NoneType
            game
            metadata : dict
            observation_space
            player
            render_mode : NoneType
            window : NoneType
            __init__(passed_game, player, render_mode)
            _get_info()
            _get_obs()
            _render_frame()*
            _step(tensordict)*
            close()
            get_acting_player()
            get_valid_sample()
            render()
            reset()
            step(action, acting_player)
          }
          DummyNet --* HardCoded : policy_net
          DummyNet --* HardCoded : target_net
          DummyNet --* Random : policy_net
          DummyNet --* Random : target_net
          ReplayMemory --* Agent : memory
          ReplayMemory --* dqn_Agent : memory
  
       </div>
  </body>
</html>
